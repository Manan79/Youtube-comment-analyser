import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import googleapiclient.discovery
from langdetect import detect
import joblib
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer, SnowballStemmer
from nltk.corpus import stopwords
import re
import matplotlib.pyplot as plt
import seaborn as sns

nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('wordnet', quiet=True)
snow = SnowballStemmer("english")

model = joblib.load("model.pkl")
vectorizer = joblib.load("tfidf.pkl")

# Set page config
st.set_page_config(
    page_title="CommentSense - YouTube Sentiment Analyzer",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
/* Main styles */
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}



/* Highlight box */
.highlight {
    
    border-left: 4px solid #ff0000;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 0 8px 8px 0;
}

/* Platform cards */
.platform-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    height: 100%;
    border-top: 4px solid #ff0000;
}

.platform-card h3 {
    color: #ff0000;
    margin-top: 0;
}

/* Button styles */
.stButton>button {
    background-color: #ff0000;
    color: white;
    border-radius: 8px;
    padding: 0.5rem 1rem;
    border: none;
    transition: all 0.3s;
}

.stButton>button:hover {
    background-color: #cc0000;
    transform: translateY(-2px);
}

/* Input styles */
.stTextInput>div>div>input {
    border-radius: 8px;
    padding: 10px;
}

/* Sidebar styles */
.stSidebar {
    background-color: #f8f9fa;
    padding: 1rem;
}

/* Metric cards */
.stMetric {
    border-radius: 8px;
    padding: 1rem;
    background-color: white;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}

/* Tab styles */
.stTabs [data-baseweb="tab-list"] {
    gap: 10px;
}

.stTabs [data-baseweb="tab"] {
    border-radius: 8px 8px 0 0 !important;
    padding: 0.5rem 1rem !important;
}

.stTabs [aria-selected="true"] {
    background-color: #ff0000 !important;
    color: white !important;
}
</style>
""", unsafe_allow_html=True)

# Sample data
DEMO_COMMENTS = [
    {"comment": "This video is amazing! I learned so much.", "sentiment": "Positive"},
    {"comment": "Worst tutorial ever, didn't explain anything", "sentiment": "Negative"},
    {"comment": "The content was okay, but could be better", "sentiment": "Neutral"},
    {"comment": "Love the presenter's energy and clear examples", "sentiment": "Positive"},
    {"comment": "Too many ads ruined the experience", "sentiment": "Negative"},
    {"comment": "Good information but poor audio quality", "sentiment": "Neutral"},
    {"comment": "Subscribed! More content like this please", "sentiment": "Positive"},
    {"comment": "Complete waste of time", "sentiment": "Negative"},
    {"comment": "The examples were helpful", "sentiment": "Positive"},
    {"comment": "Not what I expected", "sentiment": "Neutral"}
]



def youtube__details(video_url):
        api_key = "AIzaSyBTwdFySPEC0RWESNwt3eXQEuCFcBzK8Bw"
        from googleapiclient.discovery import build

        youtube = build("youtube", "v3", developerKey=api_key)

        # Get video details
        video_response = youtube.videos().list(
            part="snippet,statistics",
            id= video_url.split("v=")[-1].split("&")[0]  # Extract video ID from URL
        ).execute()

# Ge    t channel ID from video
        video_title = video_response['items'][0]['snippet']['title']
        channel_title = video_response['items'][0]['snippet']['channelTitle']
        views = video_response['items'][0]['statistics']['viewCount']
        likes = video_response['items'][0]['statistics']['likeCount']
        comment = video_response['items'][0]['statistics']['commentCount']
        picture = video_response['items'][0]['snippet']['thumbnails']['high']['url']
        
        return {
            "title": video_title,
            "channel_title": channel_title,
            "picture": picture,
            "views": views,
            "likes": likes,
            "comments": comment

        }

@st.cache_data()
def fetch_comments(video_id,  max_results=100):
    api_key = "AIzaSyBTwdFySPEC0RWESNwt3eXQEuCFcBzK8Bw"
    import googleapiclient.discovery
    import pandas as pd

    api_service_name = "youtube"
    api_version = "v3"
    DEVELOPER_KEY = api_key

    youtube = googleapiclient.discovery.build(
        api_service_name, api_version, developerKey=DEVELOPER_KEY)

    request = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=max_results,
    )
    response = request.execute()

    comments = []

    for item in response['items']:
        comment = item['snippet']['topLevelComment']['snippet']
        comments.append([
            comment['authorDisplayName'],
            comment['publishedAt'],
            comment['updatedAt'],
            comment['likeCount'],
            comment['textDisplay']
        ])

    df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])
    return df


# Simulated model prediction
# def predict_sentiment(text):
#     """Predict sentiment - replace with your actual model"""
#     cleaned_text = clean_text(text)
    
#     # Simulate prediction (replace with actual model call)
#     if "amazing" in cleaned_text or "love" in cleaned_text or "great" in cleaned_text:
#         return "Positive"
#     elif "worst" in cleaned_text or "bad" in cleaned_text or "waste" in cleaned_text:
#         return "Negative"
#     else:
#         return "Neutral"
@st.cache_data()
def analyze_sentiment(df):
    st.subheader("Top 20 comments by likes")
    st.write(df.sort_values("like_count" ,ascending=False).head(20))
    # df = df[df["Comment"].apply(is_english)]
    if df.empty:
        return pd.DataFrame(), 0.0, 0.0, 0.0, 0.0
    new_corpus = []
    for i in range(len(df)):
        review = re.sub('[^a-z A-Z]', ' ', df['text'][i])
        review = review.lower()
        review = review.split()
        review = [snow.stem(word) for word in review if word not in stopwords.words('english')]
        review = " ".join(review)
        new_corpus.append(review)
        

    X = vectorizer.transform(new_corpus)
    df["Sentiment"] = model.predict(X)
    df["Score"] = df["Sentiment"].map({
        1: "Positive ",
        0: "Neutral ",
        2: "Negative "
    })
   
    
    # st.table(df['Score']) 
    # st.table(df['Sentiment']) 

    return df


# UI started
def navigation():
    st.sidebar.image("image.png" , use_container_width=True)
    # st.sidebar.title("YouAnalyze")
    # write name in center
    st.sidebar.markdown("""
    <h1 style='text-align: center; color: #ff0000;'>YouAnalyze</h1>
    """, unsafe_allow_html=True)
    st.sidebar.markdown("""
    <p style='text-align: center; color: #333;'>Analyze YouTube Comments with AI</p>
    """, unsafe_allow_html=True)
    page = st.sidebar.radio(
        "Navigate",
        ["üè† Home", "üìä YouTube Analysis", " Model Performance Metrics" , "üöÄ Expand to Other Platforms (in Future)"],
        label_visibility="collapsed"
    )
    return page

# Home Page
def home_page():
    st.title("YouTube Comment Sentiment Analyzer")
    st.markdown("""
    <div class="highlight">
    Analyze the sentiment of YouTube comments to understand viewer reactions, 
    identify trends, and gain insights from your audience feedback.
    </div>
    """, unsafe_allow_html=True)
    
    # Demo Section
    st.header("üì∫ How It Works")
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### Simple 3-Step Process
        1. **Enter YouTube URL** - Paste any video link
        2. **Fetch Comments** - We retrieve recent comments
        3. **Get Insights** - View sentiment analysis
        
        Our advanced NLP model classifies each comment as:
        - üòä Positive
        - üò† Negative
        - üòê Neutral
        """)
        
    with col2:
        # Demo visualization
        st.image("sentiment.png", 
               use_container_width=True)
    
    # Example Analysis
    st.header("üé≠ Example Analysis")
    demo_data = pd.DataFrame(DEMO_COMMENTS)
    
    st.dataframe(demo_data.head(10), 
                height=300,
                use_container_width=True)
    
    fig, ax = plt.subplots()
    sns.countplot(x='sentiment', data=demo_data, palette=['#ff4b4b', '#4bff4b', '#4b4bff'])
    ax.set_title('Sentiment Distribution')
    st.pyplot(fig)

# YouTube Analysis Page
def youtube_analysis():
    st.title("üìπ YouTube Video Analysis")
    
    # URL Input
    video_url = st.text_input("Enter YouTube Video URL:", 
                             placeholder="https://www.youtube.com/watch?v=...")
    
    if video_url:
        st.write("Fetching video details...")
        # Simulate fetching video data (replace with your actual API calls)
        video_data = youtube__details(video_url)
        
        # Display video info
        st.subheader("Video Information")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.image(video_data["picture"],use_container_width=True)
        
        with col2:
            st.markdown(f"""
            ### {video_data["title"]}
            - üëÅÔ∏è **Channel Name:** {video_data["channel_title"]}
            - üëÅÔ∏è **Views:** {video_data["views"]}
            - üëç **Likes:** {video_data["likes"]}
            - üí¨ **Comments:** {video_data["comments"]}
            """)
        
        # Simulate fetching comments
        if st.button("Analyze Comments"):
            with st.spinner("Fetching and analyzing comments..."):
                # Use sample data (replace with actual comment fetching)
                # stop fetching data again and again
                
                comments_df = fetch_comments(video_url.split("v=")[-1].split("&")[0], max_results=100)
                
                # Predict sentiment
                
                comments_df = analyze_sentiment(comments_df)
                
                # Display results
                st.subheader("Sentiment Analysis Results")
                
                # Metrics
                pos = len(comments_df[comments_df['Score'] == 'Positive '])
                neg = len(comments_df[comments_df['Score'] == 'Negative '])
                neu = len(comments_df[comments_df['Score'] == 'Neutral '])
                
                col1, col2, col3 = st.columns(3)
                col1.metric("üòä Positive", f"{pos} ({pos/len(comments_df)*100:.1f}%)")
                col2.metric("üò† Negative", f"{neg} ({neg/len(comments_df)*100:.1f}%)")
                col3.metric("üòê Neutral", f"{neu} ({neu/len(comments_df)*100:.1f}%)")
                
                # Visualizations
                tab1, tab2 = st.tabs(["Distribution", "Raw Data"])
                
                with tab1:
                    st.subheader("Sentiment Distribution")
                    st.write("Visualize the distribution of sentiments across comments.")
                    
                    # limit the figure size using plotly
                    plt.figure(figsize=(8, 6))
                    fig = px.histogram(comments_df, x='Score', 
                                       title='Sentiment Distribution',
                                        color='Score',
                                        color_discrete_sequence=[  '#4bff4b' ,'#ff4b4b' ,'#4b4bff'])
                    fig.update_layout(bargap=0.2, xaxis_title='Sentiment', yaxis_title='Count')
                    st.plotly_chart(fig, use_container_width=True)

                    

                    # Pie chart
                    import plotly.graph_objects as go
                    st.subheader("Sentiment Breakdown")
                    pie = px.pie(comments_df, names='Score', 
                                 title='Sentiment Breakdown',
                                    color_discrete_sequence=[ '#4bff4b', '#4b4bff' , '#ff4b4b',])
                   
                    st.plotly_chart(pie, use_container_width=True)

                    top_authors = comments_df['author'].value_counts().head(10).reset_index()
                    st.write("Top 10 Commenters")
                    top_authors.columns = ['Author', 'CommentCount']
                    top_authors['CommentCount'] = top_authors['CommentCount'].astype(int)
                    top_authors['Author'] = top_authors['Author'].str.slice(0, 20)
                    st.table(top_authors)
                    fig = px.bar(top_authors, x='Author', y='CommentCount', title='Top Commenters')
                    st.plotly_chart(fig)

                    # Ratios of sentiments

                    import plotly.graph_objects as go

                    positive_ratio = (comments_df['Score'] == 'Positive ').mean() * 100
                    neutral_ratio = (comments_df['Score'] == 'Neutral ').mean() * 100
                    negative_ratio = (comments_df['Score'] == 'Negative ').mean() * 100
                    # pos = len(comments_df[comments_df['Score'] == 'Positive '])
                    total_ratio__pos = positive_ratio + neutral_ratio

                    st.subheader("Sentiment Ratios")
                    st.write("Visualize the sentiment ratios as gauges.")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        fig1 = go.Figure(go.Indicator(
                            mode="gauge+number",
                            value=positive_ratio,
                            title={'text': "Positive Sentiment %"},
                            gauge={
                                'axis': {'range': [0, 100]},
                                'bar': {'color': "#4bff4b"},
                                'steps': [
                                    {'range': [0, 33], 'color': "#ff4b4b"},
                                    {'range': [33, 67], 'color': "#ffcc00"},
                                    {'range': [67, 100], 'color': "#d4ffd4"}
                                ]
                            }
                        ))
                        st.plotly_chart(fig1, use_container_width=True)

                    with col2:
                            
                        fig2 = go.Figure(go.Indicator(
                            mode="gauge+number",
                            value=neutral_ratio,
                            title={'text': "Neutral Sentiment %"},
                            gauge={
                                'axis': {'range': [0, 100]},
                                'bar': {'color': "#4bff4b"},
                                'steps': [
                                    {'range': [0, 33], 'color': "#ff4b4b"},
                                    {'range': [33, 67], 'color': "#ffcc00"},
                                    {'range': [67, 100], 'color': "#d4ffd4"}
                                ]
                            }
                        ))
                        st.plotly_chart(fig2, use_container_width=True)
                        # st.plotly_chart(fig2, use_container_width=True)

                    with col3:
                        fig3 = go.Figure(go.Indicator(
                            mode="gauge+number",
                            value=negative_ratio,
                            title={'text': "Negative Sentiment %"},
                            gauge={
                                'axis': {'range': [0, 100]},
                                'bar': {'color': "#4bff4b"},
                                'steps': [
                                    {'range': [0, 33], 'color': "#ff4b4b"},
                                    {'range': [33, 67], 'color': "#ffcc00"},
                                    {'range': [67, 100], 'color': "#d4ffd4"}
                                ]
                            }
                        ))
                        st.plotly_chart(fig3, use_container_width=True)

                
                with tab2:
                    st.dataframe(comments_df, height=500, use_container_width=True)


# youtube video downloader


# Expansion Page
def expansion_page():
    st.title("üöÄ Expand to Other Platforms")
    st.markdown("""
    <div class="highlight">
    Our sentiment analysis model can be extended to analyze comments from various social media platforms.
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("Platform Integration Roadmap")
    
    # Platform cards
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="platform-card">
        <h3>üê¶ Twitter</h3>
        <p>Analyze tweet sentiment for hashtags or accounts</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="platform-card">
        <h3>üìò Facebook</h3>
        <p>Evaluate reactions to posts and comments</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="platform-card">
        <h3>üì∏ Instagram</h3>
        <p>Understand audience sentiment from captions</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Model details
    st.subheader("Model Architecture")
    st.markdown("""
    Our NLP model uses state-of-the-art transformer architecture fine-tuned for social media text:
    - Pretrained on 1M+ social media comments
    - 95% accuracy on validation set
    - Supports multilingual analysis
    """)

# Main app
def main():
    page = navigation()
    
    if page == "üè† Home":
        home_page()
    elif page == "üìä YouTube Analysis":
        youtube_analysis()
    elif page == " Model Performance Metrics":
        from gemini import model_metrics_page
        model_metrics_page()

    elif page == "üöÄ Expand to Other Platforms (in Future)":
        expansion_page()

if __name__ == "__main__":
    main()